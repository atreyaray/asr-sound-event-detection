{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVM File\n",
    "***\n",
    "\n",
    "1. Import libraries\n",
    "2. Load preprocessed data\n",
    "3. Train SVM\n",
    "4. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import svm classifier from sklearn\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "CV = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation Iteration:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. SVC expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39mkernel, C\u001b[38;5;241m=\u001b[39mc)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# predict the model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    174\u001b[0m         X,\n\u001b[1;32m    175\u001b[0m         y,\n\u001b[1;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    177\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    179\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    184\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    185\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    186\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    899\u001b[0m     _assert_all_finite(\n\u001b[1;32m    900\u001b[0m         array,\n\u001b[1;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. SVC expected <= 2."
     ]
    }
   ],
   "source": [
    "# list of test accuracies\n",
    "test_acc = []\n",
    "path = '../../Preprocessed Data/'\n",
    "for iteration in range(CV) :\n",
    "    \n",
    "    print(\"K-Fold Cross Validation Iteration: \", iteration)\n",
    "\n",
    "    # load data from numpy array\n",
    "    train = np.load(path +'X_train_' + str(iteration+1) + '.npy', allow_pickle=True)\n",
    "    # X_train = np.load('X_train_' + str(iteration) + '.npy')\n",
    "    # y_train = np.load('y_train_' + str(iteration) + '.npy')\n",
    "    traindf = pd.DataFrame(train, columns = [\"Tensor\", \"Target\"])\n",
    "    X_train = traindf.Tensor\n",
    "    X_train = tuple(X_train.to_list())\n",
    "    X_train = torch.stack(X_train)\n",
    "    y_train = traindf.Target.array\n",
    "    val = np.load(path +'X_val_' + str(iteration+1) + '.npy', allow_pickle=True)\n",
    "    test = np.load(path +'X_test_' + str(iteration+1) + '.npy', allow_pickle=True)\n",
    "    X_val = val[0]\n",
    "    y_val = val[1]\n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    # X_val = np.load('X_val_' + str(iteration) + '.npy')\n",
    "    # y_val = np.load('y_val_' + str(iteration) + '.npy')\n",
    "    # X_test = np.load('X_test_' + str(iteration) + '.npy')\n",
    "    # y_test = np.load('y_test_' + str(iteration) + '.npy')\n",
    "\n",
    "    # tune the hyperparameters\n",
    "    # 1. Kernel type\n",
    "    # 2. C\n",
    "    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    C = np.logspace(-3, 3)\n",
    "\n",
    "\n",
    "    val_acc = np.zeros((len(kernels), len(C)))\n",
    "\n",
    "\n",
    "    for kernel in kernels :\n",
    "        for c in C :\n",
    "            # create a svm classifier\n",
    "            svm = SVC(kernel=kernel, C=c)\n",
    "            # fit the model\n",
    "            svm.fit(X_train, y_train)\n",
    "            # predict the model\n",
    "            y_pred = svm.predict(X_val)\n",
    "            # calculate the accuracy\n",
    "            accuracy = np.sum(y_pred == y_val) / len(y_val)\n",
    "            # append the validation accuracy to the list\n",
    "            val_acc[kernels.index(kernel), C.index(c)] = accuracy\n",
    "\n",
    "    # get the best hyperparameters\n",
    "    best_kernel = kernels[np.argmax(val_acc) // len(C)]\n",
    "    best_C = C[np.argmax(val_acc) % len(C)]\n",
    "\n",
    "    # create a svm classifier with the best hyperparameters\n",
    "    svm = SVC(kernel=best_kernel, C=best_C)\n",
    "\n",
    "    # fit the model with the training data\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # predict the model with the test data\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "    # calculate the accuracy\n",
    "    accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "    print(\"Fold\", iteration, \"Test Accuracy: \", accuracy)\n",
    "\n",
    "    # append the test accuracy to the list\n",
    "    test_acc.append(accuracy)\n",
    "\n",
    "\n",
    "print('The average test accuracy is: ', np.mean(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame(train, columns = [\"Tensor\", \"Target\"])\n",
    "X_train = traindf.Tensor\n",
    "y_train = traindf.Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tuple(X_train.to_list())\n",
    "X_train = torch.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1600, 2, 64, 430])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9960)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
