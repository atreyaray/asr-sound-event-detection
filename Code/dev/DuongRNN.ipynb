{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ov3ju8fAGL",
        "outputId": "d4a4a6c1-d6d9-4226-cf91-4d1dc59d6aee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IYowEflmetop"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pydub\n",
        "import os \n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed = 42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "QT9aZ96EPfb8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDTPhKsvex38",
        "outputId": "fb3882a6-fe58-4035-c8c8-7443b42c308c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nSL_NXt7etpJ"
      },
      "outputs": [],
      "source": [
        "sound_label = [\"Dog\", \"Rooster\", \"Pig\", \"Cow\", \"Frog\", \"Cat\", \"Hen\", \"Insects (flying)\", \"Sheep\", \"Crow\"\n",
        "                ,\"Rain\", \"Sea waves\", \"Crackling fire\", \"Crickets\", \"Chirping birds\", \"Water drops\", \"Wind\", \"Pouring water\", \"Toilet flush\", \"Thunderstorm\"\n",
        "                ,\"Crying baby\", \"Sneezing\", \"Clapping\", \"Breathing\", \"Coughing\", \"Footsteps\", \"Laughing\", \"Brushing teeth\", \"Snoring\", \"Drinking, sipping\"\n",
        "                , \"Door knock\", \"Mouse click\", \"Keyboard typing\", \"Door, wood creaks\", \"Can opening\", \"washing machine\", \"Vacuum cleaner\", \"Clock alarm\", \"Clock tick\", \"Glass breaking\"\n",
        "                , \"Helicopter\", \"Chainsaw\", \"Siren\", \"Car horn\", \"Engine\", \"Train\", \"Church bells\", \"Airplane\", \"Fireworks\", \"Hand saw\"]\n",
        "sounds = dict(zip(range(50), sound_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_K5uBxdzetpR",
        "outputId": "5bfdfedb-8751-461a-ff7a-1ec206238af2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            filename  fold  target         category  esc10  src_file take\n",
              "0   1-100032-A-0.wav     1       0              dog   True    100032    A\n",
              "1  1-100038-A-14.wav     1      14   chirping_birds  False    100038    A\n",
              "2  1-100210-A-36.wav     1      36   vacuum_cleaner  False    100210    A\n",
              "3  1-100210-B-36.wav     1      36   vacuum_cleaner  False    100210    B\n",
              "4  1-101296-A-19.wav     1      19     thunderstorm  False    101296    A\n",
              "5  1-101296-B-19.wav     1      19     thunderstorm  False    101296    B\n",
              "6  1-101336-A-30.wav     1      30  door_wood_knock  False    101336    A\n",
              "7  1-101404-A-34.wav     1      34      can_opening  False    101404    A\n",
              "8   1-103298-A-9.wav     1       9             crow  False    103298    A\n",
              "9  1-103995-A-30.wav     1      30  door_wood_knock  False    103995    A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cb491b6-c32e-45c0-a316-b58af7936e08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>fold</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "      <th>esc10</th>\n",
              "      <th>src_file</th>\n",
              "      <th>take</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-100032-A-0.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>dog</td>\n",
              "      <td>True</td>\n",
              "      <td>100032</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-100038-A-14.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>chirping_birds</td>\n",
              "      <td>False</td>\n",
              "      <td>100038</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-100210-A-36.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>vacuum_cleaner</td>\n",
              "      <td>False</td>\n",
              "      <td>100210</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-100210-B-36.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>vacuum_cleaner</td>\n",
              "      <td>False</td>\n",
              "      <td>100210</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-101296-A-19.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>thunderstorm</td>\n",
              "      <td>False</td>\n",
              "      <td>101296</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1-101296-B-19.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>thunderstorm</td>\n",
              "      <td>False</td>\n",
              "      <td>101296</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1-101336-A-30.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>door_wood_knock</td>\n",
              "      <td>False</td>\n",
              "      <td>101336</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1-101404-A-34.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>can_opening</td>\n",
              "      <td>False</td>\n",
              "      <td>101404</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1-103298-A-9.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>crow</td>\n",
              "      <td>False</td>\n",
              "      <td>103298</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1-103995-A-30.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>door_wood_knock</td>\n",
              "      <td>False</td>\n",
              "      <td>103995</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cb491b6-c32e-45c0-a316-b58af7936e08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cb491b6-c32e-45c0-a316-b58af7936e08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cb491b6-c32e-45c0-a316-b58af7936e08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ASR Project/ESC-50-master/meta/esc50.csv')\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PDwkaV7Betpq"
      },
      "outputs": [],
      "source": [
        "data_path = r'/content/drive/MyDrive/ASR Project/ESC-50-master/audio/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cz7EQvI3etpV"
      },
      "outputs": [],
      "source": [
        "class AudioUtil():\n",
        "    @staticmethod\n",
        "    def open(audio_file):\n",
        "        sig, sr = torchaudio.load(audio_file)\n",
        "        return (sig,sr)\n",
        "    \n",
        "    # ----------------------------\n",
        "    # Standardizing sample rate to 44100Hz\n",
        "    # ----------------------------\n",
        "    def resample(audio, srate):\n",
        "        sig, sr = audio\n",
        "        if (sr == srate):\n",
        "            return audio\n",
        "        no_channels = sig.shape[0]\n",
        "\n",
        "        #Resample 1st channel:\n",
        "        resig = torchaudio.transforms.Resample(sr, srate)(sig[:1,:])\n",
        "        if (no_channels > 1):\n",
        "            #Resample 2nd channel and merge both\n",
        "            retwo = torchaudio.transforms.Resample(sr, srate)(sig[1:,:])\n",
        "            resig = torch.cat([resig, retwo])\n",
        "\n",
        "        return ((resig, srate))\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Some audios are mono, some are stereo. We need everything to have the same dimensions.\n",
        "    # Thus, we can either only select the first channel of stereo or duplicate the first channel of mono\n",
        "    # ----------------------------\n",
        "    @staticmethod\n",
        "    def rechannel(audio, channel):\n",
        "        sig, sr = audio\n",
        "        if (sig.shape[0]==channel):\n",
        "            return audio\n",
        "        if (channel==1):\n",
        "            resig = sig[:1,:]\n",
        "        else:\n",
        "            resig = torch.cat([sig,sig])\n",
        "\n",
        "        return ((resig, sr))\n",
        "\n",
        "    \n",
        "\n",
        "    # ----------------------------\n",
        "    # Standardize the length of the audio - that is, either pad or truncate the audio\n",
        "    # ----------------------------\n",
        "    @staticmethod\n",
        "    def resize_aud(audio, ms):\n",
        "        sig, sr = audio\n",
        "        no_rows, sig_len = sig.shape\n",
        "        max_len = sr // 1000 * ms\n",
        "\n",
        "        #Truncate\n",
        "        if (sig_len > max_len):\n",
        "            sig = sig[:, :max_len]\n",
        "        #Padding\n",
        "        elif (sig_len < max_len):\n",
        "            #Length of the paddings at the start and end of the signal\n",
        "            len_start = random.randint(0, max_len-sig_len)\n",
        "            len_end = max_len - len_start - sig_len\n",
        "\n",
        "            pad_start = torch.zeros((no_rows, len_start))\n",
        "            pad_end = torch.zeros((no_rows, len_end))\n",
        "\n",
        "            sig = torch.cat((pad_start, sig, pad_end), 1)\n",
        "\n",
        "        return (sig, sr)\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Refer to textbox_1 for the reasoning of this method\n",
        "    # ----------------------------\n",
        "    @staticmethod\n",
        "    def time_shift(aud, shift_limit):\n",
        "        sig,sr = aud\n",
        "        _, sig_len = sig.shape\n",
        "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
        "        return (sig.roll(shift_amt), sr)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Generating Spectrogram\n",
        "    # ----------------------------\n",
        "    @staticmethod\n",
        "    def spectro_gram(audio, n_mels=64, n_fft=1024, hop_len=None):\n",
        "        sig, sr = audio\n",
        "        top_db = 80 #if we have more time, we can try 80\n",
        "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "        #shape of spec is [channel (mono or stereo etc), n_mels, time]\n",
        "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "        return (spec)\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
        "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
        "    # overfitting and to help the model generalise better. The masked sections are\n",
        "    # replaced with the mean value.\n",
        "    # ----------------------------\n",
        "    @staticmethod\n",
        "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "        _, n_mels, n_steps = spec.shape\n",
        "        mask_value = spec.mean()\n",
        "        aug_spec = spec\n",
        "\n",
        "        freq_mask_param = max_mask_pct * n_mels\n",
        "        for _ in range(n_freq_masks):\n",
        "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "        time_mask_param = max_mask_pct * n_steps\n",
        "        for _ in range(n_time_masks):\n",
        "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "        return aug_spec\n",
        "    \n",
        "\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VY_QzfQzetpn"
      },
      "outputs": [],
      "source": [
        "class SoundDS(Dataset):\n",
        "  def __init__(self, df, path):\n",
        "    self.df = df\n",
        "    self.path = str(path)\n",
        "    self.duration = 5000 #our audio is 5 seconds\n",
        "    self.sr = 44100\n",
        "    self.channel = 2\n",
        "    self.shift_pct = 0.4\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "  \n",
        "  def __shape__(self):\n",
        "    return self.df.shape\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    file = self.path + self.df.loc[index, 'filename']\n",
        "    class_id = self.df.loc[index, 'target'] #the index of the label aka target\n",
        "    fold = self.df.loc[index, 'fold']\n",
        "\n",
        "    audio = AudioUtil.open(file)\n",
        "    #print(f\"Original shape {audio[0].shape} and sample rate of {audio[1]}\")\n",
        "    rechannel = AudioUtil.rechannel(audio, self.channel)\n",
        "    #print(f\"Rechanneling shape {rechannel[0].shape} and sample rate of {rechannel[1]}\")\n",
        "    resamp = AudioUtil.resample(rechannel, self.sr)\n",
        "    #print(f\"Resampling shape {resamp[0].shape} and sample rate of {resamp[1]}\")\n",
        "    padded = AudioUtil.resize_aud(resamp, self.duration)\n",
        "    #print(f\"Padded shape {padded[0].shape} and sample rate of {padded[1]}\")\n",
        "    shifted = AudioUtil.time_shift(padded, self.shift_pct)\n",
        "    #print(f\"Time shift shape {shifted[0].shape} and sample rate of {shifted[1]}\")\n",
        "    sgram = AudioUtil.spectro_gram(shifted, n_mels=64, n_fft=1024, hop_len=None)\n",
        "    #print(f\"Mel spectrogram shape {sgram.shape}\")\n",
        "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
        "    #print(f\"Augmented spectrogram shape {aug_sgram.shape} of (num_channels, Mel freq_bands, time_steps)\")\n",
        "    feature = aug_sgram\n",
        "    return feature[0].permute(1, 0), class_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qB67h6KPetpu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5Xs-d4sKetpz"
      },
      "outputs": [],
      "source": [
        "# a, b = myds[0]\n",
        "# print(a.shape)\n",
        "# print(b.shape)\n",
        "# inputs, classes = next(iter(train_dl))\n",
        "# print(\"inputs:\", inputs)\n",
        "# print(\"classes:\", classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_feature=64, out_feature=50, n_hidden=256, n_layers=2, drop_prob=0.2):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_feature = n_feature\n",
        "\n",
        "        self.lstm = nn.LSTM(self.n_feature, self.n_hidden, self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        self.fc = nn.Linear(n_hidden, out_feature)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x.shape (batch, seq_len, n_features)\n",
        "        l_out, l_hidden = self.lstm(x, hidden)\n",
        "\n",
        "        # out.shape (batch, seq_len, n_hidden*direction)\n",
        "        out = self.dropout(l_out)\n",
        "\n",
        "        # out.shape (batch, out_feature)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "\n",
        "        # return the final output and the hidden state\n",
        "        return out, l_hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        return hidden\n"
      ],
      "metadata": {
        "id": "yxm8V1I-6NfI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        output, hidden_state = model(data, model.init_hidden(hyperparameters[\"batch_size\"]))\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0: #print training stats\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss))"
      ],
      "metadata": {
        "id": "6i7X1aQX-ZC-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    y_pred, y_target = [], []\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        output, hidden_state = model(data, model.init_hidden(hyperparameters[\"batch_size\"]))\n",
        "        \n",
        "        pred = torch.max(output, dim=1).indices\n",
        "        correct += pred.eq(target).cpu().sum().item()\n",
        "        y_pred = y_pred + pred.tolist()\n",
        "        y_target = y_target + target.tolist()\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "U-UYSt1S-2jV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\"lr\": 1e-4, \"weight_decay\": 0.001, \"batch_size\": 64, \"in_feature\": 64, \"out_feature\": 50}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "myds = SoundDS(df, data_path)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}  # needed for using datasets on gpu\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=hyperparameters[\"batch_size\"], shuffle=True, drop_last=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(val_ds, batch_size=hyperparameters[\"batch_size\"], shuffle=True, drop_last=True, **kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AngnY2n_Y9i",
        "outputId": "417223a2-ee31-4a59-842c-41111362af91"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AudioLSTM(n_feature=hyperparameters[\"in_feature\"], out_feature=hyperparameters[\"out_feature\"])\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "clip = 5  # gradient clipping\n",
        "\n",
        "log_interval = 10\n",
        "for epoch in range(1, 30):\n",
        "    # scheduler.step()\n",
        "    train(model, epoch)\n",
        "    test(model, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzlVJyNW-m4c",
        "outputId": "5866e63f-63c2-41cb-be45-1fdbff9fc99c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AudioLSTM(\n",
            "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=50, bias=True)\n",
            ")\n",
            "Train Epoch: 1 [0/1600 (0%)]\tLoss: 3.913036\n",
            "Train Epoch: 1 [640/1600 (40%)]\tLoss: 3.900851\n",
            "Train Epoch: 1 [1280/1600 (80%)]\tLoss: 3.898828\n",
            "\n",
            "Test set: Accuracy: 11/400 (3%)\n",
            "\n",
            "Train Epoch: 2 [0/1600 (0%)]\tLoss: 3.849139\n",
            "Train Epoch: 2 [640/1600 (40%)]\tLoss: 3.843939\n",
            "Train Epoch: 2 [1280/1600 (80%)]\tLoss: 3.805910\n",
            "\n",
            "Test set: Accuracy: 16/400 (4%)\n",
            "\n",
            "Train Epoch: 3 [0/1600 (0%)]\tLoss: 3.808544\n",
            "Train Epoch: 3 [640/1600 (40%)]\tLoss: 3.778421\n",
            "Train Epoch: 3 [1280/1600 (80%)]\tLoss: 3.754650\n",
            "\n",
            "Test set: Accuracy: 29/400 (7%)\n",
            "\n",
            "Train Epoch: 4 [0/1600 (0%)]\tLoss: 3.676525\n",
            "Train Epoch: 4 [640/1600 (40%)]\tLoss: 3.657477\n",
            "Train Epoch: 4 [1280/1600 (80%)]\tLoss: 3.646842\n",
            "\n",
            "Test set: Accuracy: 27/400 (7%)\n",
            "\n",
            "Train Epoch: 5 [0/1600 (0%)]\tLoss: 3.579784\n",
            "Train Epoch: 5 [640/1600 (40%)]\tLoss: 3.566247\n",
            "Train Epoch: 5 [1280/1600 (80%)]\tLoss: 3.485864\n",
            "\n",
            "Test set: Accuracy: 31/400 (8%)\n",
            "\n",
            "Train Epoch: 6 [0/1600 (0%)]\tLoss: 3.441523\n",
            "Train Epoch: 6 [640/1600 (40%)]\tLoss: 3.496871\n",
            "Train Epoch: 6 [1280/1600 (80%)]\tLoss: 3.478426\n",
            "\n",
            "Test set: Accuracy: 39/400 (10%)\n",
            "\n",
            "Train Epoch: 7 [0/1600 (0%)]\tLoss: 3.362452\n",
            "Train Epoch: 7 [640/1600 (40%)]\tLoss: 3.358161\n",
            "Train Epoch: 7 [1280/1600 (80%)]\tLoss: 3.233163\n",
            "\n",
            "Test set: Accuracy: 42/400 (10%)\n",
            "\n",
            "Train Epoch: 8 [0/1600 (0%)]\tLoss: 3.226518\n",
            "Train Epoch: 8 [640/1600 (40%)]\tLoss: 3.257175\n",
            "Train Epoch: 8 [1280/1600 (80%)]\tLoss: 3.280956\n",
            "\n",
            "Test set: Accuracy: 55/400 (14%)\n",
            "\n",
            "Train Epoch: 9 [0/1600 (0%)]\tLoss: 3.027507\n",
            "Train Epoch: 9 [640/1600 (40%)]\tLoss: 3.102382\n",
            "Train Epoch: 9 [1280/1600 (80%)]\tLoss: 3.166195\n",
            "\n",
            "Test set: Accuracy: 49/400 (12%)\n",
            "\n",
            "Train Epoch: 10 [0/1600 (0%)]\tLoss: 3.243434\n",
            "Train Epoch: 10 [640/1600 (40%)]\tLoss: 3.309951\n",
            "Train Epoch: 10 [1280/1600 (80%)]\tLoss: 3.108876\n",
            "\n",
            "Test set: Accuracy: 60/400 (15%)\n",
            "\n",
            "Train Epoch: 11 [0/1600 (0%)]\tLoss: 3.209962\n",
            "Train Epoch: 11 [640/1600 (40%)]\tLoss: 2.991281\n",
            "Train Epoch: 11 [1280/1600 (80%)]\tLoss: 3.099607\n",
            "\n",
            "Test set: Accuracy: 61/400 (15%)\n",
            "\n",
            "Train Epoch: 12 [0/1600 (0%)]\tLoss: 2.959105\n",
            "Train Epoch: 12 [640/1600 (40%)]\tLoss: 2.973336\n",
            "Train Epoch: 12 [1280/1600 (80%)]\tLoss: 2.870344\n",
            "\n",
            "Test set: Accuracy: 54/400 (14%)\n",
            "\n",
            "Train Epoch: 13 [0/1600 (0%)]\tLoss: 2.829088\n",
            "Train Epoch: 13 [640/1600 (40%)]\tLoss: 2.911807\n",
            "Train Epoch: 13 [1280/1600 (80%)]\tLoss: 3.019304\n",
            "\n",
            "Test set: Accuracy: 77/400 (19%)\n",
            "\n",
            "Train Epoch: 14 [0/1600 (0%)]\tLoss: 2.895985\n",
            "Train Epoch: 14 [640/1600 (40%)]\tLoss: 2.843976\n",
            "Train Epoch: 14 [1280/1600 (80%)]\tLoss: 2.863595\n",
            "\n",
            "Test set: Accuracy: 71/400 (18%)\n",
            "\n",
            "Train Epoch: 15 [0/1600 (0%)]\tLoss: 2.829706\n",
            "Train Epoch: 15 [640/1600 (40%)]\tLoss: 3.035640\n",
            "Train Epoch: 15 [1280/1600 (80%)]\tLoss: 2.957803\n",
            "\n",
            "Test set: Accuracy: 81/400 (20%)\n",
            "\n",
            "Train Epoch: 16 [0/1600 (0%)]\tLoss: 2.777575\n",
            "Train Epoch: 16 [640/1600 (40%)]\tLoss: 2.930069\n",
            "Train Epoch: 16 [1280/1600 (80%)]\tLoss: 2.898045\n",
            "\n",
            "Test set: Accuracy: 71/400 (18%)\n",
            "\n",
            "Train Epoch: 17 [0/1600 (0%)]\tLoss: 2.836938\n",
            "Train Epoch: 17 [640/1600 (40%)]\tLoss: 2.720295\n",
            "Train Epoch: 17 [1280/1600 (80%)]\tLoss: 2.875093\n",
            "\n",
            "Test set: Accuracy: 72/400 (18%)\n",
            "\n",
            "Train Epoch: 18 [0/1600 (0%)]\tLoss: 2.697648\n",
            "Train Epoch: 18 [640/1600 (40%)]\tLoss: 2.794701\n",
            "Train Epoch: 18 [1280/1600 (80%)]\tLoss: 2.739779\n",
            "\n",
            "Test set: Accuracy: 80/400 (20%)\n",
            "\n",
            "Train Epoch: 19 [0/1600 (0%)]\tLoss: 2.870746\n",
            "Train Epoch: 19 [640/1600 (40%)]\tLoss: 2.714084\n",
            "Train Epoch: 19 [1280/1600 (80%)]\tLoss: 2.818914\n",
            "\n",
            "Test set: Accuracy: 74/400 (18%)\n",
            "\n",
            "Train Epoch: 20 [0/1600 (0%)]\tLoss: 2.728732\n",
            "Train Epoch: 20 [640/1600 (40%)]\tLoss: 2.746974\n",
            "Train Epoch: 20 [1280/1600 (80%)]\tLoss: 2.758136\n",
            "\n",
            "Test set: Accuracy: 84/400 (21%)\n",
            "\n",
            "Train Epoch: 21 [0/1600 (0%)]\tLoss: 2.620982\n",
            "Train Epoch: 21 [640/1600 (40%)]\tLoss: 2.583993\n",
            "Train Epoch: 21 [1280/1600 (80%)]\tLoss: 2.834655\n",
            "\n",
            "Test set: Accuracy: 79/400 (20%)\n",
            "\n",
            "Train Epoch: 22 [0/1600 (0%)]\tLoss: 2.825749\n",
            "Train Epoch: 22 [640/1600 (40%)]\tLoss: 2.632239\n",
            "Train Epoch: 22 [1280/1600 (80%)]\tLoss: 2.583154\n",
            "\n",
            "Test set: Accuracy: 88/400 (22%)\n",
            "\n",
            "Train Epoch: 23 [0/1600 (0%)]\tLoss: 2.585829\n",
            "Train Epoch: 23 [640/1600 (40%)]\tLoss: 2.750696\n",
            "Train Epoch: 23 [1280/1600 (80%)]\tLoss: 2.441693\n",
            "\n",
            "Test set: Accuracy: 76/400 (19%)\n",
            "\n",
            "Train Epoch: 24 [0/1600 (0%)]\tLoss: 2.459494\n",
            "Train Epoch: 24 [640/1600 (40%)]\tLoss: 2.546827\n",
            "Train Epoch: 24 [1280/1600 (80%)]\tLoss: 2.565981\n",
            "\n",
            "Test set: Accuracy: 88/400 (22%)\n",
            "\n",
            "Train Epoch: 25 [0/1600 (0%)]\tLoss: 2.723958\n",
            "Train Epoch: 25 [640/1600 (40%)]\tLoss: 2.612160\n",
            "Train Epoch: 25 [1280/1600 (80%)]\tLoss: 2.636994\n",
            "\n",
            "Test set: Accuracy: 86/400 (22%)\n",
            "\n",
            "Train Epoch: 26 [0/1600 (0%)]\tLoss: 2.536460\n",
            "Train Epoch: 26 [640/1600 (40%)]\tLoss: 2.562930\n",
            "Train Epoch: 26 [1280/1600 (80%)]\tLoss: 2.533972\n",
            "\n",
            "Test set: Accuracy: 84/400 (21%)\n",
            "\n",
            "Train Epoch: 27 [0/1600 (0%)]\tLoss: 2.509202\n",
            "Train Epoch: 27 [640/1600 (40%)]\tLoss: 2.745583\n",
            "Train Epoch: 27 [1280/1600 (80%)]\tLoss: 2.775699\n",
            "\n",
            "Test set: Accuracy: 84/400 (21%)\n",
            "\n",
            "Train Epoch: 28 [0/1600 (0%)]\tLoss: 2.809892\n",
            "Train Epoch: 28 [640/1600 (40%)]\tLoss: 2.745297\n",
            "Train Epoch: 28 [1280/1600 (80%)]\tLoss: 2.612439\n",
            "\n",
            "Test set: Accuracy: 92/400 (23%)\n",
            "\n",
            "Train Epoch: 29 [0/1600 (0%)]\tLoss: 2.536592\n",
            "Train Epoch: 29 [640/1600 (40%)]\tLoss: 2.451747\n",
            "Train Epoch: 29 [1280/1600 (80%)]\tLoss: 2.702623\n",
            "\n",
            "Test set: Accuracy: 74/400 (18%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'LSTM_2-layers_256-hidden.pt')"
      ],
      "metadata": {
        "id": "FNzLC01vO2t9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3w2ERJzFO2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cveiphCrO2z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpnMTra_O221"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_89rVsbBO26Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.5 ('pythonGeneral')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b5e820be2262a0fe2d430015389c1a2c1303250a56156485323cf96f38ca7d2c"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}