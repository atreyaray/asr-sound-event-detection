{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVM File\n",
    "***\n",
    "\n",
    "1. Import libraries\n",
    "2. Load preprocessed data\n",
    "3. Train SVM\n",
    "4. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/02/raya1/unix/Documents/Speech Recognition/asr-sound-event-detection/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import svm classifier from sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_DATA_PATH = '../Preprocessed Dataset/'\n",
    "MODEL_PATH = '../Models/'\n",
    "X = 'X_'\n",
    "y =  'y_'\n",
    "TRAIN = 'train_'\n",
    "VAL = 'val_'\n",
    "TEST = 'test_'\n",
    "path = '../Preprocessed Dataset/'\n",
    "NPY = '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation Iteration:  1\n",
      "\tKernel:  linear\n",
      "\tKernel:  poly\n",
      "\tKernel:  rbf\n",
      "\tKernel:  sigmoid\n",
      "K-Fold Cross Validation Iteration:  2\n",
      "\tKernel:  linear\n",
      "\tKernel:  poly\n",
      "\tKernel:  rbf\n",
      "\tKernel:  sigmoid\n",
      "K-Fold Cross Validation Iteration:  3\n",
      "\tKernel:  linear\n",
      "\tKernel:  poly\n",
      "\tKernel:  rbf\n",
      "\tKernel:  sigmoid\n",
      "K-Fold Cross Validation Iteration:  4\n",
      "\tKernel:  linear\n",
      "\tKernel:  poly\n",
      "\tKernel:  rbf\n",
      "\tKernel:  sigmoid\n",
      "K-Fold Cross Validation Iteration:  5\n",
      "\tKernel:  linear\n",
      "\tKernel:  poly\n",
      "\tKernel:  rbf\n",
      "\tKernel:  sigmoid\n",
      "TRAINING COMPLETED\n",
      "Best Kernel:  linear Best C:  1\n",
      "Test Accuracy:  0.38\n"
     ]
    }
   ],
   "source": [
    "# list of test accuracies\n",
    "test_acc = []\n",
    "# tune the hyperparameters\n",
    "    # 1. Kernel type\n",
    "    # 2. C\n",
    "\n",
    "TRAIN_ = False\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [1] # np.logspace(-3, 3)\n",
    "\n",
    "val_acc = np.zeros((CV, len(kernels), len(C)))\n",
    "\n",
    "for iteration in range(CV) :\n",
    "    \n",
    "    print(\"K-Fold Cross Validation Iteration: \", (iteration+ 1))\n",
    "\n",
    "    # Get path\n",
    "    TRAIN_PATH = PREPROCESSED_DATA_PATH + X + TRAIN + str(iteration+1) + NPY\n",
    "    VAL_PATH = PREPROCESSED_DATA_PATH + X + VAL + str(iteration+1) + NPY\n",
    "    TEST_PATH = PREPROCESSED_DATA_PATH + X + TEST + str(iteration+1) + NPY\n",
    "\n",
    "\n",
    "    # load data from numpy array\n",
    "    train = np.load(TRAIN_PATH, allow_pickle=True)\n",
    "    traindf = pd.DataFrame(train, columns = [\"Tensor\", \"Target\"])\n",
    "    val = np.load(VAL_PATH, allow_pickle=True)\n",
    "    valdf = pd.DataFrame(val, columns = [\"Tensor\", \"Target\"])\n",
    "    test = np.load(TEST_PATH, allow_pickle=True)\n",
    "    testdf = pd.DataFrame(test, columns = [\"Tensor\", \"Target\"])\n",
    "    \n",
    "\n",
    "    X_train = traindf.Tensor\n",
    "    X_train = np.array([i.flatten().numpy() for i in X_train.to_list()])\n",
    "    y_train = traindf.Target.to_numpy().astype(int)\n",
    "\n",
    "    X_val = valdf.Tensor\n",
    "    X_val = np.array([i.flatten().numpy() for i in X_val.to_list()])\n",
    "    y_val = valdf.Target.to_numpy().astype(int)\n",
    "\n",
    "\n",
    "    for kernel in kernels :\n",
    "        print('\\tKernel: ', kernel)\n",
    "        for c in C :\n",
    "            # create a svm classifier\n",
    "            svm = SVC(kernel=kernel, C=c)\n",
    "\n",
    "            # model name \n",
    "            filename = MODEL_PATH + 'svm-k_' + kernel + '-c_' + str(c) +'-cv_' + str(iteration) + '.sav'\n",
    "\n",
    "            if TRAIN_ :\n",
    "                # fit the model\n",
    "                svm.fit(X_train, y_train)\n",
    "                # save the model\n",
    "                pickle.dump(svm, open(filename, 'wb'))\n",
    "            \n",
    "            else :\n",
    "                # load the model\n",
    "                svm = pickle.load(open(filename, 'rb'))\n",
    "            \n",
    "            # predict the model\n",
    "            y_pred = svm.predict(X_val)\n",
    "            # calculate the accuracy\n",
    "            accuracy = np.sum(y_pred == y_val) / len(y_val)\n",
    "            # append the validation accuracy to the list\n",
    "            val_acc[iteration, kernels.index(kernel), C.index(c)] = accuracy\n",
    "\n",
    "print(\"TRAINING COMPLETED\")\n",
    "# average over the k-folds\n",
    "val_acc = np.mean(val_acc, axis=0)\n",
    "# get the best hyperparameters\n",
    "best_kernel = kernels[np.argmax(val_acc) // len(C)]\n",
    "best_c = C[np.argmax(val_acc) % len(C)]\n",
    "\n",
    "print(\"Best Kernel: \", best_kernel, \"Best C: \", best_c)\n",
    "\n",
    "for cv in range(CV) :\n",
    "    # create a svm classifier with the best hyperparameters\n",
    "    svm = SVC(kernel=best_kernel, C=best_c)\n",
    "    # Load train data\n",
    "    TRAIN_PATH = PREPROCESSED_DATA_PATH + X + TRAIN + str(cv+1) + NPY\n",
    "    train = np.load(TRAIN_PATH, allow_pickle=True)\n",
    "    traindf = pd.DataFrame(train, columns = [\"Tensor\", \"Target\"])\n",
    "\n",
    "    X_train = traindf.Tensor\n",
    "    X_train = np.array([i.flatten().numpy() for i in X_train.to_list()])\n",
    "    y_train = traindf.Target.to_numpy().astype(int)\n",
    "\n",
    "    X_test = testdf.Tensor\n",
    "    X_test = np.array([i.flatten().numpy() for i in X_test.to_list()])\n",
    "    y_test = testdf.Target.to_numpy().astype(int)\n",
    "\n",
    "    # load the model\n",
    "    filename = MODEL_PATH + 'svm-k_' + best_kernel + '-c_' + str(best_c) +'-cv_' + str(cv) + '.sav'\n",
    "    svm = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    # predict the model\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "    # append the test accuracy to the list\n",
    "    test_acc.append(accuracy)\n",
    "\n",
    "# average over the k-folds\n",
    "test_acc = np.mean(test_acc)\n",
    "\n",
    "# print the test accuracy\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log\n",
    "\n",
    "5-fold cross validation with a single kernel takes 17 minutes and Test Accuracy: 0.38 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation Iteration:  1\n",
      "\tPaths fetched!\n",
      "\tDataframe loaded\n",
      "\tFeatures extracted\n",
      "\t\tLoss:  hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.165\n",
      "\t\tLoss:  squared_hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.195\n",
      "K-Fold Cross Validation Iteration:  2\n",
      "\tPaths fetched!\n",
      "\tDataframe loaded\n",
      "\tFeatures extracted\n",
      "\t\tLoss:  hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.17\n",
      "\t\tLoss:  squared_hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.155\n",
      "K-Fold Cross Validation Iteration:  3\n",
      "\tPaths fetched!\n",
      "\tDataframe loaded\n",
      "\tFeatures extracted\n",
      "\t\tLoss:  hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.095\n",
      "\t\tLoss:  squared_hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.09\n",
      "K-Fold Cross Validation Iteration:  4\n",
      "\tPaths fetched!\n",
      "\tDataframe loaded\n",
      "\tFeatures extracted\n",
      "\t\tLoss:  hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.11\n",
      "\t\tLoss:  squared_hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.14\n",
      "K-Fold Cross Validation Iteration:  5\n",
      "\tPaths fetched!\n",
      "\tDataframe loaded\n",
      "\tFeatures extracted\n",
      "\t\tLoss:  hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.065\n",
      "\t\tLoss:  squared_hinge\n",
      "\t\tModel trained and saved\n",
      "\t\tValidation Accuracy:  0.085\n",
      "TRAINING COMPLETED\n",
      "K-Fold Cross Validation Iteration:  1\n",
      "\tDataframe loaded and Features extracted\n",
      "\tModel loaded\n",
      "K-Fold Cross Validation Iteration:  2\n",
      "\tDataframe loaded and Features extracted\n",
      "\tModel loaded\n",
      "K-Fold Cross Validation Iteration:  3\n",
      "\tDataframe loaded and Features extracted\n",
      "\tModel loaded\n",
      "K-Fold Cross Validation Iteration:  4\n",
      "\tDataframe loaded and Features extracted\n",
      "\tModel loaded\n",
      "K-Fold Cross Validation Iteration:  5\n",
      "\tDataframe loaded and Features extracted\n",
      "\tModel loaded\n",
      "Test Accuracy:  0.12\n"
     ]
    }
   ],
   "source": [
    "# list of test accuracies\n",
    "test_acc = []\n",
    "# tune the hyperparameters\n",
    "    # 1. Kernel type\n",
    "    # 2. C\n",
    "\n",
    "TRAIN_ = True\n",
    "\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# C = [1] # np.logspace(-3, 3)\n",
    "losses = ['hinge', 'squared_hinge']\n",
    "\n",
    "val_acc = np.zeros((CV, len(losses)))\n",
    "\n",
    "for iteration in range(CV) :\n",
    "    \n",
    "    print(\"K-Fold Cross Validation Iteration: \", (iteration+ 1))\n",
    "\n",
    "    # Get path\n",
    "    TRAIN_PATH = PREPROCESSED_DATA_PATH + X + TRAIN + str(iteration+1) + NPY\n",
    "    VAL_PATH = PREPROCESSED_DATA_PATH + X + VAL + str(iteration+1) + NPY\n",
    "    TEST_PATH = PREPROCESSED_DATA_PATH + X + TEST + str(iteration+1) + NPY\n",
    "    print(\"\\tPaths fetched!\")\n",
    "\n",
    "    # load data from numpy array\n",
    "    train = np.load(TRAIN_PATH, allow_pickle=True)\n",
    "    traindf = pd.DataFrame(train, columns = [\"Tensor\", \"Target\"])\n",
    "    val = np.load(VAL_PATH, allow_pickle=True)\n",
    "    valdf = pd.DataFrame(val, columns = [\"Tensor\", \"Target\"])\n",
    "    test = np.load(TEST_PATH, allow_pickle=True)\n",
    "    testdf = pd.DataFrame(test, columns = [\"Tensor\", \"Target\"])\n",
    "    print(\"\\tDataframe loaded\")\n",
    "\n",
    "    X_train = traindf.Tensor\n",
    "    X_train = np.array([i.flatten().numpy() for i in X_train.to_list()])\n",
    "    y_train = traindf.Target.to_numpy().astype(int)\n",
    "\n",
    "    X_val = valdf.Tensor\n",
    "    X_val = np.array([i.flatten().numpy() for i in X_val.to_list()])\n",
    "    y_val = valdf.Target.to_numpy().astype(int)\n",
    "    print(\"\\tFeatures extracted\")\n",
    "\n",
    "    for loss in losses :\n",
    "        print(\"\\t\\tLoss: \", loss)\n",
    "        # create a svm classifier\n",
    "        svm = SGDClassifier(loss=loss)\n",
    "\n",
    "        # model name \n",
    "        filename = MODEL_PATH + 'sgd-' + loss +'-cv-' + str(iteration) + '.sav'\n",
    "\n",
    "        if TRAIN_ :\n",
    "            # fit the model\n",
    "            svm.fit(X_train, y_train)\n",
    "            # save the model\n",
    "            pickle.dump(svm, open(filename, 'wb'))\n",
    "        \n",
    "        else :\n",
    "            # load the model\n",
    "            svm = pickle.load(open(filename, 'rb'))\n",
    "        \n",
    "        print(\"\\t\\tModel trained and saved\")\n",
    "        # predict the model\n",
    "        y_pred = svm.predict(X_val)\n",
    "        # calculate the accuracy\n",
    "        accuracy = np.sum(y_pred == y_val) / len(y_val)\n",
    "        # append the validation accuracy to the list\n",
    "        val_acc[iteration, losses.index(loss)] = accuracy\n",
    "        print(\"\\t\\tValidation Accuracy: \", accuracy)\n",
    "\n",
    "print(\"TRAINING COMPLETED\")\n",
    "# average over the k-folds\n",
    "val_acc = np.mean(val_acc, axis=0)\n",
    "\n",
    "# save the validation accuracy to a file\n",
    "np.save(MODEL_PATH + 'sgd-val-acc.npy', val_acc)\n",
    "\n",
    "# get the best loss\n",
    "best_loss = losses[np.argmax(val_acc) % len(losses)]\n",
    "\n",
    "\n",
    "for cv in range(CV) :\n",
    "    print(\"K-Fold Cross Validation Iteration: \", (cv+ 1))\n",
    "    # create a svm classifier with the best hyperparameters\n",
    "    svm = SGDClassifier(loss=best_loss)\n",
    "    # Load train data\n",
    "    TRAIN_PATH = PREPROCESSED_DATA_PATH + X + TRAIN + str(cv+1) + NPY\n",
    "    train = np.load(TRAIN_PATH, allow_pickle=True)\n",
    "    traindf = pd.DataFrame(train, columns = [\"Tensor\", \"Target\"])\n",
    "\n",
    "    X_train = traindf.Tensor\n",
    "    X_train = np.array([i.flatten().numpy() for i in X_train.to_list()])\n",
    "    y_train = traindf.Target.to_numpy().astype(int)\n",
    "\n",
    "    X_test = testdf.Tensor\n",
    "    X_test = np.array([i.flatten().numpy() for i in X_test.to_list()])\n",
    "    y_test = testdf.Target.to_numpy().astype(int)\n",
    "\n",
    "    print(\"\\tDataframe loaded and Features extracted\")\n",
    "    # load the model\n",
    "    filename = MODEL_PATH + 'sgd-' + loss +'-cv-' + str(iteration) + '.sav'\n",
    "    svm = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    print(\"\\tModel loaded\")\n",
    "    # predict the model\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "    # append the test accuracy to the list\n",
    "    test_acc.append(accuracy)\n",
    "\n",
    "# average over the k-folds\n",
    "test_acc = np.mean(test_acc)\n",
    "\n",
    "# print the test accuracy\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.121 0.133]\n"
     ]
    }
   ],
   "source": [
    "# load validation accuracy matrix\n",
    "val_acc = np.load(MODEL_PATH + 'sgd-val-acc.npy')\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03a7380898ef73343a89e1d6af6d69118674bdbb6fe3df56b6cf903f12f0b6ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
